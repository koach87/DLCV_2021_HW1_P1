{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import mean_iou_evaluate\n",
    "import viz_mask\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HW2IMGS(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        \" initial the dataset \"\n",
    "        self.X_image = None\n",
    "        self.y_label = None\n",
    "        self.X_filenames = []\n",
    "        self.y_filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        # read filenames\n",
    "        X_filenames = glob.glob(root+'/*.jpg')\n",
    "        y_filenames = glob.glob(root+'/*.png')\n",
    "        for i in range(len(X_filenames)):\n",
    "            self.X_filenames.append(os.path.splitext(os.path.basename(X_filenames[i]))[0])\n",
    "            self.y_filenames.append(os.path.splitext(os.path.basename(y_filenames[i]))[0])\n",
    "\n",
    "        self.len = len(self.X_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X_filename, y_filename = self.X_filenames[index], self.y_filenames[index]\n",
    "\n",
    "        X_image = Image.open(self.root+X_filename+'.jpg')\n",
    "        X_shape = imageio.imread(self.root+X_filename+'.jpg').shape\n",
    "\n",
    "        y_image = imageio.imread(self.root+y_filename+'.png')\n",
    "        y_label = viz_mask.read_masks(y_image, X_shape)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            X_image = self.transform(X_image)\n",
    "        return X_image, y_label\n",
    "\n",
    "    def __len__(self):\n",
    "        \" Total number of sampler in the dataset \"\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "257\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "trainset = HW2IMGS(root='p2_data/train/', transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "]))\n",
    "\n",
    "valset = HW2IMGS(root='p2_data/validation/', transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "]))\n",
    "print(len(trainset))\n",
    "print(len(valset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_loader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "valset_loader = DataLoader(valset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# # summary(vgg, (3, 512, 512))\n",
    "\n",
    "# class FCN32(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(FCN32, self).__init__()\n",
    "#         self.vgg_feature = models.vgg16(pretrained=True).features\n",
    "\n",
    "#         self.vgg_fc = nn.Sequential(\n",
    "#             nn.Conv2d(512, 4096, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(4096, 4096, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(4096, 7, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(7, 7, 32, 32),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.vgg_feature(x)\n",
    "#         x = self.vgg_fc(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# model = FCN32().to(device)  # Remember to move the model to \"device\"\n",
    "# #summary(model, (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 512, 512]           1,792\n",
      "            Conv2d-2         [-1, 64, 512, 512]           1,792\n",
      "              ReLU-3         [-1, 64, 512, 512]               0\n",
      "              ReLU-4         [-1, 64, 512, 512]               0\n",
      "            Conv2d-5         [-1, 64, 512, 512]          36,928\n",
      "            Conv2d-6         [-1, 64, 512, 512]          36,928\n",
      "              ReLU-7         [-1, 64, 512, 512]               0\n",
      "              ReLU-8         [-1, 64, 512, 512]               0\n",
      "         MaxPool2d-9         [-1, 64, 256, 256]               0\n",
      "        MaxPool2d-10         [-1, 64, 256, 256]               0\n",
      "           Conv2d-11        [-1, 128, 256, 256]          73,856\n",
      "           Conv2d-12        [-1, 128, 256, 256]          73,856\n",
      "             ReLU-13        [-1, 128, 256, 256]               0\n",
      "             ReLU-14        [-1, 128, 256, 256]               0\n",
      "           Conv2d-15        [-1, 128, 256, 256]         147,584\n",
      "           Conv2d-16        [-1, 128, 256, 256]         147,584\n",
      "             ReLU-17        [-1, 128, 256, 256]               0\n",
      "             ReLU-18        [-1, 128, 256, 256]               0\n",
      "        MaxPool2d-19        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-20        [-1, 128, 128, 128]               0\n",
      "           Conv2d-21        [-1, 256, 128, 128]         295,168\n",
      "           Conv2d-22        [-1, 256, 128, 128]         295,168\n",
      "             ReLU-23        [-1, 256, 128, 128]               0\n",
      "             ReLU-24        [-1, 256, 128, 128]               0\n",
      "           Conv2d-25        [-1, 256, 128, 128]         590,080\n",
      "           Conv2d-26        [-1, 256, 128, 128]         590,080\n",
      "             ReLU-27        [-1, 256, 128, 128]               0\n",
      "             ReLU-28        [-1, 256, 128, 128]               0\n",
      "           Conv2d-29        [-1, 256, 128, 128]         590,080\n",
      "           Conv2d-30        [-1, 256, 128, 128]         590,080\n",
      "             ReLU-31        [-1, 256, 128, 128]               0\n",
      "             ReLU-32        [-1, 256, 128, 128]               0\n",
      "        MaxPool2d-33          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-34          [-1, 256, 64, 64]               0\n",
      "           Conv2d-35          [-1, 512, 64, 64]       1,180,160\n",
      "           Conv2d-36          [-1, 512, 64, 64]       1,180,160\n",
      "             ReLU-37          [-1, 512, 64, 64]               0\n",
      "             ReLU-38          [-1, 512, 64, 64]               0\n",
      "           Conv2d-39          [-1, 512, 64, 64]       2,359,808\n",
      "           Conv2d-40          [-1, 512, 64, 64]       2,359,808\n",
      "             ReLU-41          [-1, 512, 64, 64]               0\n",
      "             ReLU-42          [-1, 512, 64, 64]               0\n",
      "           Conv2d-43          [-1, 512, 64, 64]       2,359,808\n",
      "           Conv2d-44          [-1, 512, 64, 64]       2,359,808\n",
      "             ReLU-45          [-1, 512, 64, 64]               0\n",
      "             ReLU-46          [-1, 512, 64, 64]               0\n",
      "        MaxPool2d-47          [-1, 512, 32, 32]               0\n",
      "        MaxPool2d-48          [-1, 512, 32, 32]               0\n",
      "           Conv2d-49          [-1, 512, 32, 32]       2,359,808\n",
      "           Conv2d-50          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-51          [-1, 512, 32, 32]               0\n",
      "             ReLU-52          [-1, 512, 32, 32]               0\n",
      "           Conv2d-53          [-1, 512, 32, 32]       2,359,808\n",
      "           Conv2d-54          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-55          [-1, 512, 32, 32]               0\n",
      "             ReLU-56          [-1, 512, 32, 32]               0\n",
      "           Conv2d-57          [-1, 512, 32, 32]       2,359,808\n",
      "           Conv2d-58          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-59          [-1, 512, 32, 32]               0\n",
      "             ReLU-60          [-1, 512, 32, 32]               0\n",
      "        MaxPool2d-61          [-1, 512, 16, 16]               0\n",
      "        MaxPool2d-62          [-1, 512, 16, 16]               0\n",
      "         Upsample-63          [-1, 512, 32, 32]               0\n",
      "  ConvTranspose2d-64          [-1, 256, 64, 64]         524,544\n",
      "             ReLU-65          [-1, 256, 64, 64]               0\n",
      "  ConvTranspose2d-66          [-1, 7, 512, 512]         114,695\n",
      "             ReLU-67          [-1, 7, 512, 512]               0\n",
      "================================================================\n",
      "Total params: 30,068,615\n",
      "Trainable params: 30,068,615\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 2330.00\n",
      "Params size (MB): 114.70\n",
      "Estimated Total Size (MB): 2447.70\n",
      "----------------------------------------------------------------\n",
      "FCN8(\n",
      "  (vgg_feature): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (p0_p3): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (p3_p4): Sequential(\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (p4_p5): Sequential(\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (up2x): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "  (ct8x): Sequential(\n",
      "    (0): ConvTranspose2d(256, 7, kernel_size=(8, 8), stride=(8, 8))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (ct): Sequential(\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class FCN8(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN8, self).__init__()\n",
    "        self.vgg_feature = models.vgg16(pretrained=True).features\n",
    "\n",
    "        self.p0_p3 = self.vgg_feature[:17]\n",
    "        self.p3_p4 = self.vgg_feature[17:24]\n",
    "        self.p4_p5 = self.vgg_feature[24:31]\n",
    "        \n",
    "        #upsample 2x\n",
    "        self.up2x = nn.Upsample(scale_factor= 2 , mode='bilinear', align_corners=True)\n",
    "        #upsample 8x\n",
    "        self.ct8x = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256,7,8,8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        #shape channel from 512 to 256\n",
    "        self.ct = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512,256,2,stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        p3 = self.p0_p3(x)\n",
    "        p4 = self.p3_p4(p3)\n",
    "        p5 = self.p4_p5(p4)\n",
    "\n",
    "        p4p5 = self.up2x(p5) + p4\n",
    "        p4p5 = self.ct(p4p5)\n",
    "        p3p4p5 = p4p5+p3\n",
    "\n",
    "        x = self.ct8x(p3p4p5)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = FCN8().to(device)  # Remember to move the model to \"device\"\n",
    "summary(model, (3, 512, 512))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.randn((1,512,16,16))  #P5\n",
    "# b = torch.randn((1,512,32,32))  #P4\n",
    "# c = torch.randn((1,256,64,64))  #P3\n",
    "\n",
    "# up2times = nn.Upsample(scale_factor= 2 , mode='bilinear', align_corners=True)\n",
    "# cc = nn.ConvTranspose2d(512,256,2,stride=2)\n",
    "# convtranspose8x = nn.ConvTranspose2d(256,7,8,8)\n",
    "\n",
    "\n",
    "# ab =up2times(a)+b\n",
    "# # print(ab.shape)\n",
    "# ab = cc(ab)\n",
    "# abc = ab+c\n",
    "# # print(abc.shape)\n",
    "# abc = convtranspose8x(abc)\n",
    "# # print(abc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = models.vgg16(pretrained=True).features\n",
    "# b = a[:17]\n",
    "# c = a[17:24]\n",
    "# d = a[24:31]\n",
    "\n",
    "# print(b)\n",
    "# print(c)\n",
    "# print(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# summary(model, (3,512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_acc_his, train_loss_his = [], []\n",
    "val_acc_his, val_loss_his = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval=200):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()  # Important: set training mode\n",
    "\n",
    "    for ep in range(epoch):\n",
    "        outs = np.empty((0,512,512))\n",
    "        tars = np.empty((0,512,512))\n",
    "        iteration = 0\n",
    "        correct = 0\n",
    "        total_train = 0\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(trainset_loader)):\n",
    "\n",
    "            loss = 0.0\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            output = torch.nn.functional.log_softmax(output, dim=1)\n",
    "            target = torch.tensor(target, dtype=torch.long, device=device)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "            # get the index of the max log-probability\n",
    "            total_train += target.nelement()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            pred = pred.eq(target.view_as(pred))\n",
    "\n",
    "\n",
    "\n",
    "            # print(pred)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            iteration+=1\n",
    "            \n",
    "\n",
    "            #prepare data for mean-IOU\n",
    "            pred = output.max(1, keepdim=False)[1].cpu().numpy()\n",
    "            labels = target.cpu().numpy()\n",
    "            outs = np.concatenate((outs,pred))\n",
    "            tars = np.concatenate((tars,labels))\n",
    "\n",
    "\n",
    "            if (iteration % log_interval == 0):\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                    ep+1, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item(),\n",
    "                    correct, total_train,\n",
    "                    100. * correct / total_train))\n",
    "                \n",
    "        mean_iou_evaluate.mean_iou_score(outs,tars)\n",
    "        train_acc_his.append(100. * correct / len(trainset_loader.dataset))\n",
    "        train_loss_his.append(loss.item())\n",
    "        val(model)  # Evaluate at the end of each epoch\n",
    "        scheduler.step()\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(train_acc_his)\n",
    "    plt.plot(val_acc_his)\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.title('model loss')\n",
    "    plt.plot(train_loss_his)\n",
    "    plt.plot(val_loss_his)\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()  # Important: set evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total_val = 0\n",
    "    outs = np.empty((0,512,512))\n",
    "    tars = np.empty((0,512,512))\n",
    "\n",
    "    with torch.no_grad():  # This will free the GPU memory used for back-prop\n",
    "        for data, target in valset_loader:\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            output = torch.nn.functional.log_softmax(output, dim=1)\n",
    "            # print(output.shape, target.shape)\n",
    "            target = torch.tensor(target, dtype=torch.long, device=device)\n",
    "            # target.clone().detach()\n",
    "            val_loss += criterion(output, target).item()\n",
    "            total_val += target.nelement()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "            pred = output.max(1, keepdim=False)[1].cpu().numpy()\n",
    "            labels = target.cpu().numpy()\n",
    "\n",
    "            outs = np.concatenate((outs,pred))\n",
    "            tars = np.concatenate((tars,labels))\n",
    "            \n",
    "    miou = mean_iou_evaluate.mean_iou_score(outs,tars)\n",
    "    if(miou>0.63):\n",
    "        torch.save(model, ('./done.pth'),_use_new_zipfile_serialization=False)\n",
    "\n",
    "    val_loss /= len(valset_loader.dataset)\n",
    "    print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, total_val,\n",
    "        100. * correct / total_val))\n",
    "\n",
    "    val_acc_his.append(100. * correct / len(valset_loader.dataset))\n",
    "    val_loss_his.append(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def outputpred(model,filename):\n",
    "#     X = Image.open(filename)\n",
    "#     X = X.to(device)\n",
    "#     masks = model(X)\n",
    "#     print(masks)\n",
    "#     # cs = np.unique(masks)\n",
    "\n",
    "#     # for c in cs:\n",
    "#     #     mask = np.zeros((img.shape[0], img.shape[1]))\n",
    "#     #     ind = np.where(masks==c)\n",
    "#     #     mask[ind[0], ind[1]] = 1\n",
    "#     #     img = viz_mask.viz_data(img, mask, color=viz_mask.cmap[c])\n",
    "#     #     imageio.imsave('./exp.png', np.uint8(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputpred(model,'p2_data\\\\validation\\\\0236_sat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]<ipython-input-12-32c28201d4ae>:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target, dtype=torch.long, device=device)\n",
      " 40%|████      | 200/500 [05:25<10:23,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [796/2000 (40%)]\tLoss: 1.684623, Accuracy: 125724445/209715200 (60%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 400/500 [13:57<05:00,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1596/2000 (80%)]\tLoss: 1.109191, Accuracy: 241866879/419430400 (58%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [19:26<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class #0 : 0.39494\n",
      "class #1 : 0.67618\n",
      "class #2 : 0.01168\n",
      "class #3 : 0.34094\n",
      "class #4 : 0.18117\n",
      "class #5 : 0.05814\n",
      "\n",
      "mean_iou: 0.277174\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-04731e6e7b8b>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target, dtype=torch.long, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class #0 : 0.62341\n",
      "class #1 : 0.75551\n",
      "class #2 : 0.00727\n",
      "class #3 : 0.43449\n",
      "class #4 : 0.46274\n",
      "class #5 : 0.26940\n",
      "\n",
      "mean_iou: 0.425471\n",
      "\n",
      "\n",
      "Val set: Average loss: 0.1912, Accuracy: 51543914/67371008 (77%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 200/500 [05:19<10:09,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [796/2000 (40%)]\tLoss: 0.449719, Accuracy: 118026824/209715200 (56%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 400/500 [13:46<05:01,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [1596/2000 (80%)]\tLoss: 0.496973, Accuracy: 238450206/419430400 (57%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [19:10<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class #0 : 0.62911\n",
      "class #1 : 0.78609\n",
      "class #2 : 0.01236\n",
      "class #3 : 0.62929\n",
      "class #4 : 0.51653\n",
      "class #5 : 0.36513\n",
      "\n",
      "mean_iou: 0.489753\n",
      "\n",
      "class #0 : 0.64527\n",
      "class #1 : 0.83178\n",
      "class #2 : 0.04407\n",
      "class #3 : 0.69975\n",
      "class #4 : 0.49315\n",
      "class #5 : 0.52045\n",
      "\n",
      "mean_iou: 0.539079\n",
      "\n",
      "\n",
      "Val set: Average loss: 0.1398, Accuracy: 55594367/67371008 (83%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 200/500 [05:19<10:17,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [796/2000 (40%)]\tLoss: 0.943802, Accuracy: 118412357/209715200 (56%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 400/500 [13:41<04:53,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [1596/2000 (80%)]\tLoss: 0.600293, Accuracy: 239718497/419430400 (57%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [19:02<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class #0 : 0.66193\n",
      "class #1 : 0.81390\n",
      "class #2 : 0.04147\n",
      "class #3 : 0.67437\n",
      "class #4 : 0.54643\n",
      "class #5 : 0.45081\n",
      "\n",
      "mean_iou: 0.531484\n",
      "\n",
      "class #0 : 0.66189\n",
      "class #1 : 0.84214\n",
      "class #2 : 0.08092\n",
      "class #3 : 0.69907\n",
      "class #4 : 0.54025\n",
      "class #5 : 0.53970\n",
      "\n",
      "mean_iou: 0.560662\n",
      "\n",
      "\n",
      "Val set: Average loss: 0.1303, Accuracy: 55945525/67371008 (83%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 200/500 [05:20<10:10,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [796/2000 (40%)]\tLoss: 0.510732, Accuracy: 117256395/209715200 (56%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 261/500 [07:33<09:15,  2.32s/it]"
     ]
    }
   ],
   "source": [
    "train(model, epoch=20)\n",
    "# val(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 512, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test code for Mean iou\n",
    "# a = torch.randn(1, 7, 3, 3)\n",
    "# # print(a)\n",
    "# print(a)\n",
    "# a = torch.torch.nn.functional.log_softmax(a, dim=1)\n",
    "# print(a.shape)\n",
    "# print(a)\n",
    "# a = a.numpy()\n",
    "# print(a.shape)\n",
    "outs = np.empty((0,512,512))\n",
    "b = torch.randn(7,512,512).numpy()\n",
    "b= np.concatenate((outs,b))\n",
    "b.shape\n",
    "# b = torch.argmax(b,dim = 0)\n",
    "# b = b.numpy()\n",
    "# mean_iou_evaluate.mean_iou_score(a,b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zhuanlan.zhihu.com/p/32506912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "outs = np.empty((0,512,512))\n",
    "outs.shape\n",
    "print(outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/ching-i/fully-convolutional-networks-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80-246aa68ce4ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/JustinHeaton/fully-convolutional-networks/blob/master/FCN32.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.malaoshi.top/show_1EF53OZZLiWQ.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(30,7, 512, 512)\n",
    "# c = a.max(1, keepdim=True)[1]\n",
    "# c = a.max(1)[1].numpy()\n",
    "b = torch.argmax(a, dim=1).numpy()\n",
    "# print(c)\n",
    "# print(c.shape)\n",
    "# print(b.shape)\n",
    "# mean_iou_evaluate.mean_iou_score(c,c)\n",
    "\n",
    "print(np.concatenate((b, b), axis=0).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN8(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # feats = list(models.vgg16(pretrained=True).features.children())\n",
    "\n",
    "        # self.feats = nn.Sequential(*feats[0:9])\n",
    "        # self.feat3 = nn.Sequential(*feats[10:16])\n",
    "        # self.feat4 = nn.Sequential(*feats[17:23])\n",
    "        # self.feat5 = nn.Sequential(*feats[24:30])\n",
    "\n",
    "        # for m in self.modules():\n",
    "        #     if isinstance(m, nn.Conv2d):\n",
    "        #         m.requires_grad = False\n",
    "\n",
    "        self.fconn = nn.Sequential(\n",
    "            nn.Conv2d(512, 4096, 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Conv2d(4096, 4096, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "        )\n",
    "        self.score_feat3 = nn.Conv2d(256, num_classes, 1)\n",
    "        self.score_feat4 = nn.Conv2d(512, num_classes, 1)\n",
    "        self.score_fconn = nn.Conv2d(4096, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.feats(x)\n",
    "        feat3 = self.feat3(feats)\n",
    "        feat4 = self.feat4(feat3)\n",
    "        feat5 = self.feat5(feat4)\n",
    "        fconn = self.fconn(feat5)\n",
    "\n",
    "        score_feat3 = self.score_feat3(feat3)\n",
    "        score_feat4 = self.score_feat4(feat4)\n",
    "        score_fconn = self.score_fconn(fconn)\n",
    "\n",
    "        score = F.upsample_bilinear(score_fconn, score_feat4.size()[2:])\n",
    "        score += score_feat4\n",
    "        score = F.upsample_bilinear(score, score_feat3.size()[2:])\n",
    "        score += score_feat3\n",
    "\n",
    "        return F.upsample_bilinear(score, x.size()[2:])\n",
    "model = FCN8(7).to(device,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNET, self).__init__()\n",
    "\n",
    "        self.vgg_feature = models.vgg16(pretrained=True).features[:24]\n",
    "        # print(self.vgg_feature)\n",
    "        self.vgg_u1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 512, 2, 2),\n",
    "        )\n",
    "        # print(self.vgg_u1)\n",
    "        self.vgg_u2 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256,2,2),\n",
    "        )\n",
    "        # print(self.vgg_u2)\n",
    "        self.vgg_u3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128,2,2),\n",
    "        )\n",
    "        # print(self.vgg_u3)\n",
    "        self.vgg_u4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64,2,2),\n",
    "        )\n",
    "        # print(self.vgg_u4)\n",
    "        self.vgg_u5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 7, 1),\n",
    "        )\n",
    "        # print(self.vgg_u5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        f1 = self.vgg_feature[:3]\n",
    "        f2 = self.vgg_feature[4:8]\n",
    "        f3 = self.vgg_feature[9:15]\n",
    "        f4 = self.vgg_feature[16:22]\n",
    "        \n",
    "        out1 = self.vgg_feature(x)\n",
    "        out2 = self.vgg_feature(f1)\n",
    "        out3 = self.vgg_feature(f2)\n",
    "        out4 = self.vgg_feature(f3)\n",
    "        x = self.vgg_feature(f4)\n",
    "\n",
    "        x = self.vgg_u1(x)\n",
    "        x = torch.cat((out4,x),dim=1)\n",
    "        x = self.vgg_u2(x)\n",
    "        x = torch.cat((out3,x),dim=1)\n",
    "        x = self.vgg_u3(x)\n",
    "        x = torch.cat((out2,x),dim=1)\n",
    "        x = self.vgg_u4(x)\n",
    "        x = torch.cat((out1,x),dim=1)\n",
    "        x = self.vgg_u5(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = UNET().to(device) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
