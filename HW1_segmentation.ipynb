{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import mean_iou_evaluate\n",
    "import viz_mask\n",
    "import imageio\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HW2IMGS(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        \" initial the dataset \"\n",
    "        self.X_image = None\n",
    "        self.y_label = None\n",
    "        self.X_filenames = []\n",
    "        self.y_filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        # read filenames\n",
    "        X_filenames = glob.glob(root+'/*.jpg')\n",
    "        y_filenames = glob.glob(root+'/*.png')\n",
    "        for i in range(len(X_filenames)):\n",
    "            self.X_filenames.append(os.path.splitext(\n",
    "                os.path.basename(X_filenames[i]))[0])\n",
    "            self.y_filenames.append(os.path.splitext(\n",
    "                os.path.basename(y_filenames[i]))[0])\n",
    "\n",
    "        self.len = len(self.X_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X_filename, y_filename = self.X_filenames[index], self.y_filenames[index]\n",
    "\n",
    "        X_image = Image.open(self.root+X_filename+'.jpg')\n",
    "        X_shape = imageio.imread(self.root+X_filename+'.jpg').shape\n",
    "\n",
    "        y_image = imageio.imread(self.root+y_filename+'.png')\n",
    "        y_label = viz_mask.read_masks(y_image, X_shape)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            X_image = self.transform(X_image)\n",
    "\n",
    "        \" get a sample from the dataset \"\n",
    "        # if torch.cuda.is_available():\n",
    "        #   X_image, y_label = X_image.cuda(), y_label.cuda()\n",
    "\n",
    "        return X_image, y_label\n",
    "\n",
    "    def __len__(self):\n",
    "        \" Total number of sampler in the dataset \"\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "257\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "trainset = HW2IMGS(root='p2_data/train/', transform=transforms.Compose([\n",
    "    # transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "]))\n",
    "\n",
    "valset = HW2IMGS(root='p2_data/validation/', transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "]))\n",
    "print(len(trainset))\n",
    "print(len(valset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_loader = DataLoader(trainset, batch_size=2, shuffle=True)\n",
    "valset_loader = DataLoader(valset, batch_size=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# summary(vgg, (3, 512, 512))\n",
    "\n",
    "\n",
    "class FCN32(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN32, self).__init__()\n",
    "        self.vgg_feature = models.vgg16(pretrained=True).features\n",
    "\n",
    "        self.vgg_fc = nn.Sequential(\n",
    "            nn.Conv2d(512, 4096, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4096, 4096, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4096, 7, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(7, 7, 32, 32),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vgg_feature(x)\n",
    "        x = self.vgg_fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = FCN32().to(device)  # Remember to move the model to \"device\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(model, (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_acc_his, train_loss_his = [], []\n",
    "val_acc_his, val_loss_his = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval=200):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()  # Important: set training mode\n",
    "    for ep in range(epoch):\n",
    "        iteration = 0\n",
    "        correct = 0\n",
    "        total_train = 0\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(trainset_loader)):\n",
    "\n",
    "            loss = 0.0\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            output = torch.nn.functional.log_softmax(output, dim=1)\n",
    "            target = torch.tensor(target, dtype=torch.long, device=device)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "            # get the index of the max log-probability\n",
    "\n",
    "            total_train += target.nelement()\n",
    "\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            pred = pred.eq(target.view_as(pred))\n",
    "            # print(pred)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            iteration+=1\n",
    "\n",
    "\n",
    "\n",
    "            if (iteration % log_interval == 0):\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                    ep+1, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item(),\n",
    "                    correct, total_train,\n",
    "                    100. * correct / total_train))\n",
    "                \n",
    "\n",
    "        train_acc_his.append(100. * correct / len(trainset_loader.dataset))\n",
    "        train_loss_his.append(loss.item())\n",
    "        val(model)  # Evaluate at the end of each epoch\n",
    "        scheduler.step()\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(train_acc_his)\n",
    "    plt.plot(val_acc_his)\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.title('model loss')\n",
    "    plt.plot(train_loss_his)\n",
    "    plt.plot(val_loss_his)\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()  # Important: set evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total_val = 0\n",
    "    outs = np.empty((0,512,512))\n",
    "    tars = []\n",
    "\n",
    "    with torch.no_grad():  # This will free the GPU memory used for back-prop\n",
    "        for data, target in valset_loader:\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            tars.append(target)\n",
    "\n",
    "            output = torch.nn.functional.log_softmax(output, dim=1)\n",
    "            # print(output.shape, target.shape)\n",
    "            target = torch.tensor(target, dtype=torch.long, device=device)\n",
    "            # target.clone().detach()\n",
    "            val_loss += criterion(output, target)\n",
    "            total_val += target.nelement()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "            pred = output.max(1, keepdim=False)[1].cpu().numpy()\n",
    "            labels = target.cpu().numpy()\n",
    "            # print(pred.shape)\n",
    "            # print(labels.shape)\n",
    "            mean_iou_evaluate.mean_iou_score(pred,labels)\n",
    "            # outs.append(output.max(1)[1].numpy())\n",
    "            \n",
    "    for i in range(len(outs)):\n",
    "        pass\n",
    "\n",
    "    val_loss /= len(valset_loader.dataset)\n",
    "    print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, total_val,\n",
    "        100. * correct / total_val))\n",
    "\n",
    "    val_acc_his.append(100. * correct / len(valset_loader.dataset))\n",
    "    val_loss_his.append(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-d0ba7dd4a2f3>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target, dtype=torch.long, device=device)\n",
      "c:\\Users\\koach\\DLCV\\HW1\\mean_iou_evaluate.py:39: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  iou = tp / (tp_fp + tp_fn - tp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class #0 : 0.00000\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.50351\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00877\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00000\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.01014\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00664\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00818\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.02088\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00008\n",
      "class #5 : 0.00066\n",
      "\n",
      "mean_iou: 0.003602\n",
      "\n",
      "class #0 : 0.00139\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00001\n",
      "class #3 : nan\n",
      "class #4 : 0.00001\n",
      "class #5 : 0.13579\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.02748\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00031\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.01685\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: 0.002809\n",
      "\n",
      "class #0 : 0.02832\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: 0.004721\n",
      "\n",
      "class #0 : 0.02189\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00002\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00201\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: 0.000335\n",
      "\n",
      "class #0 : 0.00197\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.37427\n",
      "\n",
      "mean_iou: 0.062708\n",
      "\n",
      "class #0 : 0.00000\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.01707\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.27864\n",
      "\n",
      "mean_iou: 0.049286\n",
      "\n",
      "class #0 : 0.01480\n",
      "class #1 : nan\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00003\n",
      "class #5 : 0.42908\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00876\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.38247\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.02370\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00000\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00000\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: 0.000000\n",
      "\n",
      "class #0 : 0.02245\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00011\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00000\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.01547\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00000\n",
      "class #1 : 0.00000\n",
      "class #2 : nan\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.01757\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00842\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00316\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.44840\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00969\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.01239\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00000\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: 0.000000\n",
      "\n",
      "class #0 : 0.00551\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00007\n",
      "class #3 : nan\n",
      "class #4 : 0.00056\n",
      "class #5 : 0.26238\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00231\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.01206\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00146\n",
      "class #5 : 0.15797\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.02296\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00092\n",
      "class #5 : 0.10792\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00576\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00023\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00778\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00549\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.01261\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: 0.002101\n",
      "\n",
      "class #0 : 0.03417\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.54908\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.01177\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00056\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00017\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.34494\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00296\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00126\n",
      "class #5 : 0.06775\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00000\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: 0.000000\n",
      "\n",
      "class #0 : 0.00894\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00042\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.02900\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00019\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.38665\n",
      "\n",
      "mean_iou: 0.064473\n",
      "\n",
      "class #0 : 0.00466\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.10474\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.02657\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.01690\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00978\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00021\n",
      "class #5 : 0.07434\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.00050\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.01294\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.02239\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.04300\n",
      "\n",
      "mean_iou: 0.010899\n",
      "\n",
      "class #0 : 0.02359\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : 0.00000\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00174\n",
      "\n",
      "mean_iou: 0.004223\n",
      "\n",
      "class #0 : 0.01686\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00000\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.02453\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00002\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.05962\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.02309\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.00217\n",
      "\n",
      "mean_iou: nan\n",
      "\n",
      "class #0 : 0.01231\n",
      "class #1 : 0.00000\n",
      "class #2 : 0.00000\n",
      "class #3 : nan\n",
      "class #4 : 0.00000\n",
      "class #5 : 0.12487\n",
      "\n",
      "mean_iou: nan\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9a6eed229c5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train(model, epoch=10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-d0ba7dd4a2f3>\u001b[0m in \u001b[0;36mval\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m# get the index of the max log-probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train(model, epoch=10)\n",
    "val(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 512, 512)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-2ccff8338994>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# b = torch.argmax(b,dim = 0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# test code for Mean iou\n",
    "# a = torch.randn(1, 7, 3, 3)\n",
    "# # print(a)\n",
    "# print(a)\n",
    "# a = torch.torch.nn.functional.log_softmax(a, dim=1)\n",
    "# print(a.shape)\n",
    "# print(a)\n",
    "# a = a.numpy()\n",
    "# print(a.shape)\n",
    "b = torch.randn(7,512,512).numpy()\n",
    "b= np.concatenate(b,b)\n",
    "b.shape\n",
    "# b = torch.argmax(b,dim = 0)\n",
    "# b = b.numpy()\n",
    "# mean_iou_evaluate.mean_iou_score(a,b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zhuanlan.zhihu.com/p/32506912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "outs = np.empty((0,512,512))\n",
    "outs.shape\n",
    "print(outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/ching-i/fully-convolutional-networks-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80-246aa68ce4ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/JustinHeaton/fully-convolutional-networks/blob/master/FCN32.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.malaoshi.top/show_1EF53OZZLiWQ.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(30,7, 512, 512)\n",
    "# c = a.max(1, keepdim=True)[1]\n",
    "c = a.max(1)[1].numpy()\n",
    "b = torch.argmax(a, dim=1).numpy()\n",
    "# print(c)\n",
    "print(c.shape)\n",
    "# print(b.shape)\n",
    "mean_iou_evaluate.mean_iou_score(c,c)\n",
    "\n",
    "# print(np.concatenate((b, b), axis=0).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
