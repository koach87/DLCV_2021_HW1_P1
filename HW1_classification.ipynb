{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W2YoyBqJ4mnY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# from google.colab import drive\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "6HxN3BwdTr-b",
    "outputId": "e2e87b6c-3832-40b7-b93b-90760f587c06"
   },
   "outputs": [],
   "source": [
    "# upload images from googledrive\n",
    "# drive.mount('/content/gdrive')\n",
    "# %cd ./gdrive/MyDrive/2021-DLCV-HW/HW1/\n",
    "# !unzip hw1_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JVX7goCqUO9Z"
   },
   "outputs": [],
   "source": [
    "class HWIMGS(Dataset):\n",
    "  def __init__(self, root, transform=None):\n",
    "    \" initial the dataset \"\n",
    "    self.image = None\n",
    "    self.label = None\n",
    "    self.filenames = []\n",
    "    self.root = root;\n",
    "    self.transform = transform\n",
    "\n",
    "    #read filenames\n",
    "    filenames = glob.glob(root+'/*.png')\n",
    "    for fn in filenames:\n",
    "        #store data, label\n",
    "        reg = fn\n",
    "        \n",
    "#         colab:/*.png\n",
    "#         jupyter:\\*.png\n",
    "        reg = fn.split('\\\\')[-1].split('_')[0]\n",
    "#         print(reg)\n",
    "        reg = int(reg)\n",
    "        self.filenames.append((fn, reg))\n",
    "\n",
    "    self.len = len(filenames)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    \" get a sample from the dataset \"\n",
    "    img_fn, label = self.filenames[index]\n",
    "    # if torch.cuda.is_available():\n",
    "    #   img_fn, label = img_fn.cuda(), label.cuda()\n",
    "    image = Image.open(img_fn)\n",
    "    if self.transform is not None:\n",
    "      image = self.transform(image)\n",
    "    \n",
    "    return image, label\n",
    "  \n",
    "  def __len__(self):\n",
    "    \" Total number of sampler in the dataset \"\n",
    "    return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ht4dlE0u1yOE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "trainset = HWIMGS(root='p1_data/train_50', transform=transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),\n",
    "#     transforms.RandomRotation(2.8),\n",
    "#     transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]))\n",
    "\n",
    "valset = HWIMGS(root='p1_data/val_50', transform=transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]))\n",
    "print(len(trainset))\n",
    "print(len(valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "k-SCGVTU5cT2"
   },
   "outputs": [],
   "source": [
    "trainset_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "valset_loader = DataLoader(valset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MhteG8I8GXDS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KEpdzt1w2IWE"
   },
   "outputs": [],
   "source": [
    "# vgg16 = models.vgg16(pretrained=True)\n",
    "# vgg16.classifier[6]= nn.Sequential(\n",
    "#     nn.Dropout(0.2),\n",
    "#     nn.Linear(4096, 50)\n",
    "# )\n",
    "# # vgg16.classifier[6]=nn.Linear(4096,50)\n",
    "# vgg16 = vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 256]         131,328\n",
      "             ReLU-69                  [-1, 256]               0\n",
      "          Dropout-70                  [-1, 256]               0\n",
      "           Linear-71                   [-1, 50]          12,850\n",
      "================================================================\n",
      "Total params: 11,320,690\n",
      "Trainable params: 11,320,690\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 43.19\n",
      "Estimated Total Size (MB): 106.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "# print(resnet18)\n",
    "# summary(resnet18, (3, 224, 224))\n",
    "resnet18.fc= nn.Sequential(\n",
    "    \n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    \n",
    "#     nn.Linear(256, 100),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm1d(100),\n",
    "#     nn.Dropout(0.3),\n",
    "    \n",
    "    nn.Linear(256, 50)\n",
    ")\n",
    "\n",
    "for param in resnet18.parameters():\n",
    "    resnet18.requires_grad = True\n",
    "resnet18 = resnet18.to(device)\n",
    "summary(resnet18, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "h-oscdhZLmjr"
   },
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval=100):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()  # Important: set training mode\n",
    "    correct = 0\n",
    "    \n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        correct = 0\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(trainset_loader), 1):\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "#             if iteration % log_interval == 0:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "            ep+1, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "            100. * batch_idx / len(trainset_loader), loss.item(),\n",
    "            correct, len(trainset_loader.dataset),\n",
    "            100. * correct / len(trainset_loader.dataset)))\n",
    "#             iteration += 1\n",
    "        val(model)\n",
    "        val(model, scheduler) # Evaluate at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "z6ka47yON28p"
   },
   "outputs": [],
   "source": [
    "def val(model, scheduler):\n",
    "# def val(model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()  # Important: set evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): # This will free the GPU memory used for back-prop\n",
    "        for data, target in valset_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss /= len(valset_loader.dataset)\n",
    "    print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(valset_loader.dataset),\n",
    "        100. * correct / len(valset_loader.dataset)))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dq5DUlWGN5ST",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 704/704 [02:22<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [2816/22500 (100%)]\tLoss: 2.079556, Accuracy: 10717/22500 (48%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 1/704 [00:00<02:17,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0465, Accuracy: 1436/2500 (57%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 704/704 [02:22<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [2816/22500 (100%)]\tLoss: 3.561085, Accuracy: 1817/22500 (8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/704 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0954, Accuracy: 433/2500 (17%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 704/704 [02:20<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [2816/22500 (100%)]\tLoss: 1.157820, Accuracy: 10271/22500 (46%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                  | 1/704 [00:00<02:21,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0503, Accuracy: 1379/2500 (55%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▉                                                                    | 105/704 [00:20<02:03,  4.85it/s]"
     ]
    }
   ],
   "source": [
    "train(resnet18, epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQADnanKlY88"
   },
   "outputs": [],
   "source": [
    "torch.save(resnet18, './resnet18_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFghYqeU09Bk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
