{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W2YoyBqJ4mnY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# from google.colab import drive\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "6HxN3BwdTr-b",
    "outputId": "e2e87b6c-3832-40b7-b93b-90760f587c06"
   },
   "outputs": [],
   "source": [
    "# upload images from googledrive\n",
    "# drive.mount('/content/gdrive')\n",
    "# %cd ./gdrive/MyDrive/2021-DLCV-HW/HW1/\n",
    "# !unzip hw1_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JVX7goCqUO9Z"
   },
   "outputs": [],
   "source": [
    "class HWIMGS(Dataset):\n",
    "  def __init__(self, root, transform=None):\n",
    "    \" initial the dataset \"\n",
    "    self.image = None\n",
    "    self.label = None\n",
    "    self.filenames = []\n",
    "    self.root = root;\n",
    "    self.transform = transform\n",
    "\n",
    "    #read filenames\n",
    "    filenames = glob.glob(root+'/*.png')\n",
    "    for fn in filenames:\n",
    "        #store data, label\n",
    "        reg = fn\n",
    "        \n",
    "#         colab:/*.png\n",
    "#         jupyter:\\*.png\n",
    "        reg = fn.split('\\\\')[-1].split('_')[0]\n",
    "#         print(reg)\n",
    "        reg = int(reg)\n",
    "        self.filenames.append((fn, reg))\n",
    "\n",
    "    self.len = len(filenames)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    \" get a sample from the dataset \"\n",
    "    img_fn, label = self.filenames[index]\n",
    "    # if torch.cuda.is_available():\n",
    "    #   img_fn, label = img_fn.cuda(), label.cuda()\n",
    "    image = Image.open(img_fn)\n",
    "    if self.transform is not None:\n",
    "      image = self.transform(image)\n",
    "    \n",
    "    return image, label\n",
    "  \n",
    "  def __len__(self):\n",
    "    \" Total number of sampler in the dataset \"\n",
    "    return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ht4dlE0u1yOE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "trainset = HWIMGS(root='p1_data/train_50', transform=transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]))\n",
    "\n",
    "valset = HWIMGS(root='p1_data/val_50', transform=transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]))\n",
    "print(len(trainset))\n",
    "print(len(valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "k-SCGVTU5cT2"
   },
   "outputs": [],
   "source": [
    "trainset_loader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "valset_loader = DataLoader(valset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(trainset_loader)\n",
    "# images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a7ec80f77de4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Image tensor in each batch:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Image tensor in each batch:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "# print('Image tensor in each batch:', images.shape, images.dtype)\n",
    "# print('Image tensor in each batch:', labels.shape, labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MhteG8I8GXDS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KEpdzt1w2IWE"
   },
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "vgg16.classifier[6]= nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(4096, 50)\n",
    ")\n",
    "# vgg16.classifier[6]=nn.Linear(4096,50)\n",
    "vgg16 = vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# resnet18 = models.resnet18(pretrained=True)\n",
    "# # print(resnet18)\n",
    "# # summary(resnet18, (3, 224, 224))\n",
    "# resnet18.fc= nn.Sequential(\n",
    "    \n",
    "#     nn.Linear(512, 256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm1d(256),\n",
    "#     nn.Dropout(0.3),\n",
    "    \n",
    "# #     nn.Linear(256, 100),\n",
    "# #     nn.ReLU(),\n",
    "# #     nn.BatchNorm1d(100),\n",
    "# #     nn.Dropout(0.3),\n",
    "    \n",
    "#     nn.Linear(256, 50)\n",
    "# )\n",
    "# resnet18 = resnet18.to(device)\n",
    "# summary(resnet18, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# resnet101 = models.resnet101(pretrained=True)\n",
    "\n",
    "# resnet101.fc = nn.Sequential(\n",
    "    \n",
    "# #     nn.Linear(2048, 256),\n",
    "# #     nn.ReLU(),\n",
    "# #     nn.BatchNorm1d(256),\n",
    "# #     nn.Dropout(0.3),\n",
    "    \n",
    "# #     nn.Linear(256, 100),\n",
    "# #     nn.ReLU(),\n",
    "# #     nn.BatchNorm1d(100),\n",
    "# #     nn.Dropout(0.3),\n",
    "    \n",
    "#     nn.Linear(2048, 50)\n",
    "# )\n",
    "# resnet101 = resnet101.to(device)\n",
    "# summary(resnet101, (3, 224, 224))\n",
    "# print(resnet101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "h-oscdhZLmjr"
   },
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval=100):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()  # Important: set training mode\n",
    "    \n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(trainset_loader), 1):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if iteration % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep+1, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "                    100. * batch_idx / len(trainset_loader), loss.item()))\n",
    "            iteration += 1\n",
    "        val(model, scheduler) # Evaluate at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "z6ka47yON28p"
   },
   "outputs": [],
   "source": [
    "def val(model, scheduler):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()  # Important: set evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): # This will free the GPU memory used for back-prop\n",
    "        for data, target in valset_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss /= len(valset_loader.dataset)\n",
    "    print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(valset_loader.dataset),\n",
    "        100. * correct / len(valset_loader.dataset)))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dq5DUlWGN5ST",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                               | 1/5625 [00:01<2:06:13,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [4/22500 (0%)]\tLoss: 4.193804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                           | 101/5625 [01:05<1:16:10,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [404/22500 (2%)]\tLoss: 3.864074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▊                                                                          | 201/5625 [02:09<1:14:39,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [804/22500 (4%)]\tLoss: 3.980115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                         | 301/5625 [03:14<1:13:38,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1204/22500 (5%)]\tLoss: 3.896211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▍                                                                       | 401/5625 [04:18<1:12:58,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1604/22500 (7%)]\tLoss: 4.119132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▊                                                                      | 501/5625 [05:22<1:11:12,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [2004/22500 (9%)]\tLoss: 3.949313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▏                                                                    | 601/5625 [06:27<1:09:25,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [2404/22500 (11%)]\tLoss: 3.850469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▌                                                                   | 701/5625 [07:31<1:08:59,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [2804/22500 (12%)]\tLoss: 3.915371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▉                                                                  | 801/5625 [08:35<1:07:20,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3204/22500 (14%)]\tLoss: 3.971312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▎                                                                | 901/5625 [09:40<1:05:23,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3604/22500 (16%)]\tLoss: 3.724684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▌                                                              | 1001/5625 [10:44<1:04:11,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [4004/22500 (18%)]\tLoss: 3.944809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▉                                                             | 1101/5625 [11:48<1:02:31,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [4404/22500 (20%)]\tLoss: 3.928359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▏                                                           | 1201/5625 [12:52<1:01:56,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [4804/22500 (21%)]\tLoss: 3.898521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████                                                            | 1301/5625 [13:56<59:55,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [5204/22500 (23%)]\tLoss: 3.846349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                          | 1401/5625 [15:01<58:56,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [5604/22500 (25%)]\tLoss: 3.848243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████▊                                                         | 1501/5625 [16:05<56:54,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6004/22500 (27%)]\tLoss: 3.936123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▏                                                       | 1601/5625 [17:09<55:57,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6404/22500 (28%)]\tLoss: 4.023210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████▌                                                      | 1701/5625 [18:13<54:08,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6804/22500 (30%)]\tLoss: 3.890316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████▉                                                     | 1801/5625 [19:18<53:04,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [7204/22500 (32%)]\tLoss: 3.938806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████▎                                                   | 1901/5625 [20:22<51:40,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [7604/22500 (34%)]\tLoss: 3.892848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████▋                                                  | 2001/5625 [21:26<50:09,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [8004/22500 (36%)]\tLoss: 3.985591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████▏                                                | 2101/5625 [22:30<49:04,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [8404/22500 (37%)]\tLoss: 3.976887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████▌                                               | 2201/5625 [23:34<47:19,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [8804/22500 (39%)]\tLoss: 3.882454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████▉                                              | 2301/5625 [24:38<45:33,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [9204/22500 (41%)]\tLoss: 3.902848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████▎                                            | 2401/5625 [25:43<44:38,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [9604/22500 (43%)]\tLoss: 3.820957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████▋                                           | 2501/5625 [26:47<43:27,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [10004/22500 (44%)]\tLoss: 3.837223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████▊                                           | 2510/5625 [26:52<33:08,  1.57it/s]"
     ]
    }
   ],
   "source": [
    "train(vgg16, epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQADnanKlY88"
   },
   "outputs": [],
   "source": [
    "torch.save(model.resnet50(), './resnet18_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFghYqeU09Bk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
