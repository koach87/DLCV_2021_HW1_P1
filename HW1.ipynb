{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W2YoyBqJ4mnY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# from google.colab import drive\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "6HxN3BwdTr-b",
    "outputId": "e2e87b6c-3832-40b7-b93b-90760f587c06"
   },
   "outputs": [],
   "source": [
    "# upload images from googledrive\n",
    "# drive.mount('/content/gdrive')\n",
    "# %cd ./gdrive/MyDrive/2021-DLCV-HW/HW1/\n",
    "# !unzip hw1_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JVX7goCqUO9Z"
   },
   "outputs": [],
   "source": [
    "class HWIMGS(Dataset):\n",
    "  def __init__(self, root, transform=None):\n",
    "    \" initial the dataset \"\n",
    "    self.image = None\n",
    "    self.label = None\n",
    "    self.filenames = []\n",
    "    self.root = root;\n",
    "    self.transform = transform\n",
    "\n",
    "    #read filenames\n",
    "    filenames = glob.glob(root+'/*.png')\n",
    "    for fn in filenames:\n",
    "        #store data, label\n",
    "        reg = fn\n",
    "        \n",
    "#         colab:/*.png\n",
    "#         jupyter:\\*.png\n",
    "        reg = fn.split('\\\\')[-1].split('_')[0]\n",
    "#         print(reg)\n",
    "        reg = int(reg)\n",
    "        self.filenames.append((fn, reg))\n",
    "\n",
    "    self.len = len(filenames)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    \" get a sample from the dataset \"\n",
    "    img_fn, label = self.filenames[index]\n",
    "    # if torch.cuda.is_available():\n",
    "    #   img_fn, label = img_fn.cuda(), label.cuda()\n",
    "    image = Image.open(img_fn)\n",
    "    if self.transform is not None:\n",
    "      image = self.transform(image)\n",
    "    \n",
    "    return image, label\n",
    "  \n",
    "  def __len__(self):\n",
    "    \" Total number of sampler in the dataset \"\n",
    "    return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ht4dlE0u1yOE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500\n",
      "2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:715: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "trainset = HWIMGS(root='p1_data/train_50', transform=transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]))\n",
    "\n",
    "valset = HWIMGS(root='p1_data/val_50', transform=transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]))\n",
    "print(len(trainset))\n",
    "print(len(valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "k-SCGVTU5cT2"
   },
   "outputs": [],
   "source": [
    "trainset_loader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "valset_loader = DataLoader(valset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(trainset_loader)\n",
    "# images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Image tensor in each batch:', images.shape, images.dtype)\n",
    "# print('Image tensor in each batch:', labels.shape, labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MhteG8I8GXDS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KEpdzt1w2IWE"
   },
   "outputs": [],
   "source": [
    "# vgg16 = models.vgg16(pretrained=True)\n",
    "# vgg16.classifier[6]= nn.Sequential(\n",
    "#     nn.Dropout(0.2),\n",
    "#     nn.Linear(4096, 50)\n",
    "# )\n",
    "# # vgg16.classifier[6]=nn.Linear(4096,50)\n",
    "# vgg16 = vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 50]          25,650\n",
      "================================================================\n",
      "Total params: 11,202,162\n",
      "Trainable params: 11,202,162\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.73\n",
      "Estimated Total Size (MB): 106.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "# print(resnet18)\n",
    "# summary(resnet18, (3, 224, 224))\n",
    "resnet18.fc= nn.Sequential(\n",
    "    \n",
    "    nn.Linear(512, 50),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm1d(256),\n",
    "#     nn.Dropout(0.3),\n",
    "    \n",
    "#     nn.Linear(256, 100),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm1d(100),\n",
    "#     nn.Dropout(0.3),\n",
    "    \n",
    "#     nn.Linear(256, 50)\n",
    ")\n",
    "resnet18 = resnet18.to(device)\n",
    "summary(resnet18, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# resnet101 = models.resnet101(pretrained=True)\n",
    "\n",
    "# resnet101.fc = nn.Sequential(\n",
    "    \n",
    "# #     nn.Linear(2048, 256),\n",
    "# #     nn.ReLU(),\n",
    "# #     nn.BatchNorm1d(256),\n",
    "# #     nn.Dropout(0.3),\n",
    "    \n",
    "# #     nn.Linear(256, 100),\n",
    "# #     nn.ReLU(),\n",
    "# #     nn.BatchNorm1d(100),\n",
    "# #     nn.Dropout(0.3),\n",
    "    \n",
    "#     nn.Linear(2048, 50)\n",
    "# )\n",
    "# resnet101 = resnet101.to(device)\n",
    "# summary(resnet101, (3, 224, 224))\n",
    "# print(resnet101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "h-oscdhZLmjr"
   },
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval=100):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()  # Important: set training mode\n",
    "    correct = 0\n",
    "    \n",
    "    iteration = 0\n",
    "    for ep in range(epoch):\n",
    "        correct = 0\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(trainset_loader), 1):\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "#             if iteration % log_interval == 0:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "            ep+1, batch_idx * len(data), len(trainset_loader.dataset),\n",
    "            100. * batch_idx / len(trainset_loader), loss.item(),\n",
    "            correct, len(trainset_loader.dataset),\n",
    "            100. * correct / len(trainset_loader.dataset)))\n",
    "#             iteration += 1\n",
    "        val(model, scheduler) # Evaluate at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "z6ka47yON28p"
   },
   "outputs": [],
   "source": [
    "def val(model, scheduler):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()  # Important: set evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): # This will free the GPU memory used for back-prop\n",
    "        for data, target in valset_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss /= len(valset_loader.dataset)\n",
    "    print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(valset_loader.dataset),\n",
    "        100. * correct / len(valset_loader.dataset)))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dq5DUlWGN5ST",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/5625 [00:00<?, ?it/s]C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
      "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
      "To get the qr decomposition consider using torch.linalg.qr.\n",
      "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
      "The unpacking of the solution, as in\n",
      "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
      "should be replaced with\n",
      "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  ..\\aten\\src\\ATen\\LegacyTHFunctionsCPU.cpp:389.)\n",
      "  res = torch.lstsq(b_matrix, a_matrix)[0]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5625/5625 [04:51<00:00, 19.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [22500/22500 (100%)]\tLoss: 1.479118, Accuracy: 4287/22500 (19%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 3/5625 [00:00<04:19, 21.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.5638, Accuracy: 930/2500 (37%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5625/5625 [04:43<00:00, 19.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [22500/22500 (100%)]\tLoss: 1.881288, Accuracy: 8447/22500 (38%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 2/5625 [00:00<05:16, 17.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.4333, Accuracy: 1269/2500 (51%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5625/5625 [04:42<00:00, 19.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [22500/22500 (100%)]\tLoss: 3.165186, Accuracy: 11706/22500 (52%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 2/5625 [00:00<05:05, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.3935, Accuracy: 1367/2500 (55%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5625/5625 [04:40<00:00, 20.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [22500/22500 (100%)]\tLoss: 2.155373, Accuracy: 13448/22500 (60%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 2/5625 [00:00<04:49, 19.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.3287, Accuracy: 1543/2500 (62%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5625/5625 [04:39<00:00, 20.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [22500/22500 (100%)]\tLoss: 0.663683, Accuracy: 14780/22500 (66%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 2/5625 [00:00<05:52, 15.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.2930, Accuracy: 1651/2500 (66%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5625/5625 [04:42<00:00, 19.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [22500/22500 (100%)]\tLoss: 1.091581, Accuracy: 15794/22500 (70%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 3/5625 [00:00<04:21, 21.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.2720, Accuracy: 1686/2500 (67%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5625/5625 [04:41<00:00, 19.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [22500/22500 (100%)]\tLoss: 1.324097, Accuracy: 16721/22500 (74%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 3/5625 [00:00<04:22, 21.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.2796, Accuracy: 1691/2500 (68%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5625/5625 [04:41<00:00, 19.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [22500/22500 (100%)]\tLoss: 0.613996, Accuracy: 17528/22500 (78%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 3/5625 [00:00<04:22, 21.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.2632, Accuracy: 1746/2500 (70%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5625/5625 [04:42<00:00, 19.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [22500/22500 (100%)]\tLoss: 1.785501, Accuracy: 18142/22500 (81%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 3/5625 [00:00<04:18, 21.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.2847, Accuracy: 1751/2500 (70%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5625/5625 [04:43<00:00, 19.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [22500/22500 (100%)]\tLoss: 0.055488, Accuracy: 18681/22500 (83%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 2/5625 [00:00<05:07, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.2521, Accuracy: 1833/2500 (73%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 5532/5625 [04:38<00:04, 20.91it/s]"
     ]
    }
   ],
   "source": [
    "train(resnet18, epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQADnanKlY88"
   },
   "outputs": [],
   "source": [
    "# torch.save(model.resnet50(), './resnet18_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFghYqeU09Bk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
